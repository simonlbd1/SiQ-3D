{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d56b3e",
   "metadata": {},
   "source": [
    "The basic procedures include:\n",
    "(1) Import packages\n",
    "(2) Initialize parameters for tracking\n",
    "(3) Prepare data and models\n",
    "(4) Optimize the image segmentation parameters \n",
    "(5) Optimize the tracking parameters\n",
    "(6) Track the following volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254e3f3",
   "metadata": {},
   "source": [
    "# Step 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.display import display, HTML\n",
    "from SiQ3D.tumorTracker import Tracker\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8990c6e",
   "metadata": {},
   "source": [
    "# Step 2. Initialize parameters for tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb6021",
   "metadata": {},
   "source": [
    "Image parameters:\\\n",
    "•\tvolume_num: number of volumes (i.e., time points) of the images to be tracked\\\n",
    "•\txyz_size: size of a 3D frame: (height, width, depth), unit: voxels\\\n",
    "•\tz_xy_ratio: resolution (m/voxel) ratio between the z (depth) and x-y plane\\\n",
    "Segmentation parameters:\\\n",
    "•\tnoise_level: usually the intensity of the non-cell region; used for image normalization.\\\n",
    "•\tmin_size: the minimal cell size; used for removing the small objects.\\\n",
    "•\tmin_distance: the minimum value of the distance used in 3D watershed for cell segmentation\\\n",
    "Tracking parameters:\\\n",
    "•\tbeta_tk: set it higher/lower to get more/less coherent predictions for cell positions.\\\n",
    "•\tlambda_tk: set it higher/lower to get more/less coherent predictions for cell positions.\\\n",
    "•\tmaxiter_tk: the number of iterations for implementing the tracking algorithm (FFN + PR-GLS). The higher the value, the more accurate but slower.\\\n",
    "File information:\\\n",
    "•\tfolder_path: the path of the folder to store data, model and tracking results. We recommend users to create a folder under the same directory containing the jupyter notebook file, i.e., “./xxx” (“xxx” is the folder name).\\\n",
    "•\timage_name: file name of the images to be tracked. Users should name their image sequences in the format of “xxx_Tk_Zm.tif”, where “xxx” is the prefix of the file name, and “k” and “m” are the index number of time point and z stack, respectively. For example, “tumor_T123_Z023” indicates this is a tumor cell image at time point #123 and z-stack #23. “k” and “m” are n-bit integers (e.g., “k” is a 3-bit integer if the dataset consists of hundreds of time points in total). With “k” and “m” as n-bit integers, the parameter image_name should be set in the Python format as,\n",
    " image_name=“xxx_T%0ni_Z%0ni.tif”\\\n",
    "•\tunet_model_file: file name of the pre-trained 3D U-Net model.\\\n",
    "•\tffn_model_file: file name of the pre-trained ffn model.\\\n",
    "•\tclassifier_file: file name of the pre-trained phenotype classifier.\\\n",
    "\n",
    "Cell phenotyping parameters:\\\n",
    "•\tphenotyping: this parameter should be True or False, the default value is True. if True, users have to provide information about classifier_file, and tumor cell phenotyping will be implemented; if False, users do not need to provide information about classifier_file, and tumor cell phenotyping won’t be implemented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba4c14",
   "metadata": {},
   "source": [
    "Multiple folders will be automatically created to store data, models and the tracking results, including:\\\n",
    "data: to store the images to be tracked.\\\n",
    "auto_vol1: to store the automatically generated segmentation results at volume 1.\\\n",
    "manual_vol1: to store the manually corrected segmentation results at volume 1.\\\n",
    "tracking_information: to store the spatial coordinates of the tracked cells.\\\n",
    "models: to store the pre-trained and re-trained models.\\\n",
    "segmentation_results: to store the segmentation results generated by 3D U-Net + watershed (before tracking) .\\\n",
    "track_results: to store the tracking results (images of labels).\\\n",
    "anim: to store the animation of the tracking process (used for program diagnosis).\\\n",
    "models/unet_weights: to store the re-trained unet weights.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8720ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(volume_num=10, xyz_size=(360, 360, 27), z_xy_ratio=4.6, noise_level=60, min_size=100, min_distance=10,\n",
    "                  beta_tk=600, lambda_tk=0.1, maxiter_tk=10, folder_path=os.path.abspath(\"./tumor_tracking\"), \n",
    "                  image_name=\"tumor_t%03i_z%03i.tif\", unet_model_file=\"unet3_pretrained.h5\", \n",
    "                  ffn_model_file=\"ffn_pretrained.h5\", classifier_file=\"tumor_classifier_pretrained.h5\", \n",
    "                  phenotyping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afd05d2",
   "metadata": {},
   "source": [
    "Reset the segmentation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b54fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.set_segmentation(noise_level=10, min_size=30, min_distance=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b44b2d",
   "metadata": {},
   "source": [
    "# Step 3. Prepare data and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5a9e3",
   "metadata": {},
   "source": [
    "Move the 2D image (z-stacks) sequences from the 3D movies to the created folder data.\\\n",
    "Move the pre-trained 3D U-Net, FFN model and classifier files to the created folder models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b64f5",
   "metadata": {},
   "source": [
    "# Step 4. Optimize the image segmentation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ce4f95",
   "metadata": {},
   "source": [
    "Segment cells at volume 1 and display the results (Maximum Intensity Projection of the 3D image into 2D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d38795",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.segment_vol1()\n",
    "tracker.draw_segresult()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b961df",
   "metadata": {},
   "source": [
    "Load the manual segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.load_manual_seg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c036bb4",
   "metadata": {},
   "source": [
    "Retrain the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.retrain_unet(iteration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9e4d6",
   "metadata": {},
   "source": [
    "By default, the program will re-train 3D U-Net for 10 epochs. If other number of epochs is desired, users can modify the parameter iteration=n, where n is the epoch number. Users can manually stop the training by pressing Ctrl+C if the val_loss no longer decreases. After re-training the 3D U-Net, select the epoch number that generates the best cell region predictions (e.g., epoch=8 as used below). If the initial pre-trained U-Net performs better, set epoch=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.select_unet_weights(epoch=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51361914",
   "metadata": {},
   "source": [
    "Use the newly trained U-Net to segment volume 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.segment_vol1()\n",
    "tracker.draw_segresult()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da5d8d",
   "metadata": {},
   "source": [
    "# Step 5. Optimize the tracking parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2115ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.initiate_tracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604c93a",
   "metadata": {},
   "source": [
    "Test the matching between volume 1 and a target volume (e.g., target_volume=5 as used above), and then display the matching results with symbols as follows:\\\n",
    "•\tRed circles: cells in vol 1.\\\n",
    "•\tBlue cross: cells detected by 3D U-Net in the target volume\\\n",
    "•\tBlue arrows: predicted transformation (cell movements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d04b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_tracking, results = tracker.match(target_volume=5)\n",
    "HTML(anim_tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b4d8b5",
   "metadata": {},
   "source": [
    "Reset the tracking parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.set_tracking(beta_tk=800, lambda_tk=0.5, maxiter_tk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_tracking, results = tracker.match(target_volume=5)\n",
    "HTML(anim_tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa781d58",
   "metadata": {},
   "source": [
    "# Step 6. Track the following volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig, ax = tracker.subplots_tracking()\n",
    "tracker.track(fig, ax, from_volume=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025aad3",
   "metadata": {},
   "source": [
    "Display the processes as an animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd19ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "track_anim = tracker.replay_track_animation()\n",
    "HTML(track_anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc1c44",
   "metadata": {},
   "source": [
    "Save cell coordinates and phenotyping results as csv file in folder tracking_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88cb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.save_coordinates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621bfd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
